{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Actividad03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carlinpe/Algorithm-to-win-a-sports-bet-with-python/blob/main/Actividad03/Actividad03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EtfxYyJXNVd"
      },
      "source": [
        "#Actividad 03\n",
        "```\n",
        "Curso     : Minería de Datos 2021-2\n",
        "Docente   : Carlos Fernando Montoya Cubas\n",
        "Autor     : Carlos Enrique Quispe Chambilla\n",
        "Fecha     : 24/11/2021\n",
        "Lugar     : Cusco, Perú, 2021.\n",
        "Proposito : Implementar el algoritmo de Apriori\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrYLc7dRfOvu"
      },
      "source": [
        "##**Librerias**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69VKnuvzehQQ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections\n",
        "from collections import defaultdict"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfkIhXUc2aVG"
      },
      "source": [
        "## **1. Implementar las siguientes funciones principales**\n",
        "*   **get_frequent_itemsets(playlists, min_support):** Recibe la estructura de datos que contiene a las playlists y retorna una estructura con los itemsets fre-cuentes, bajo un umbral mínimo de soporte.\n",
        "\n",
        "*   **generate_association_rules(frequent_itemsets, confidence, lift):** Recibe los itemsets frecuentes generados por la función anterior y retorna las reglas de asociación. Se le puede entregar umbrales de confianza o lift para las reglas que se retornarán. Por ejemplo, si se llama esta función con los ar- gumentos confidence = 0.5 y lift = 1.2, se espera que se retornen aquellas reglas que cumplan con una confianza ≥ 0.5 y un lift ≥ 1.2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N05aa7XG4-Cm"
      },
      "source": [
        "#### **Funcion: get_frequent_itemsets(playlists, min_support)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZwojcrWNsJb"
      },
      "source": [
        "# Funcion para estructurar los datos con un umbral minimo de aceptacion\n",
        "def get_frequent_itemsets(playlists, min_support):\n",
        "  # Listamos los datos\n",
        "  playlists = list(playlists.item().values())\n",
        "  playlists = [set(playlist) for playlist in playlists]\n",
        "  canciones = [item for sublist in playlists for item in sublist]\n",
        "  # Determinamos la frecuencia de cada cancion\n",
        "  contador_canciones = pd.Series(data=canciones).value_counts().to_dict()\n",
        "  # Se crea un diccionario de canciones\n",
        "  canciones_playlists = collections.defaultdict(set)\n",
        "  # Determinamos un valor para cada playlist\n",
        "  for index, playlist in enumerate(playlists):\n",
        "      for cancion in playlist:\n",
        "          canciones_playlists[cancion].add(index)\n",
        "  canciones_playlists = canciones_playlists\n",
        "  # Determinamos las canciones mas rankeadas en cada playlist\n",
        "  contador = {cancion: veces for cancion, veces in contador_canciones.items() if veces / len(playlists) >= min_support}\n",
        "  itemsets = [{cancion} for cancion in contador.keys()]\n",
        "  # Obtenemos los itemsets mas frecuentes\n",
        "  itemsets_frecuentes = {}\n",
        "  itemsets_frecuentes[1] = sorted(contador.items(), key=lambda x: x[1], reverse=True)\n",
        "  itemsets_frecuentes_tamaño = []\n",
        "  # Inicializamos contador en 2\n",
        "  k = 2\n",
        "  actual = itemsets  \n",
        "  while len(actual) != 0:\n",
        "    # Generamos itemsets\n",
        "    combinaciones = set() \n",
        "    m = k - 2\n",
        "    for candidato in actual: \n",
        "      candidato = list(candidato)\n",
        "      for aux in actual:\n",
        "        aux = list(aux)\n",
        "        union = True\n",
        "        for i in range(k - 2):\n",
        "          if candidato[i] != aux[i]:\n",
        "              union = False\n",
        "              break\n",
        "        if not union:\n",
        "          continue\n",
        "        if candidato[k - 2] < aux[k - 2]:\n",
        "          c = candidato + [aux[k - 2]]\n",
        "          c = frozenset(sorted(c))\n",
        "          combinaciones.add(c)\n",
        "    # Determinamos que el itemset cumpla cumpla con el umbral minimo de soporte\n",
        "    contadorDecombinaciones = {}   \n",
        "    playlist_tamanio = len(playlists)   \n",
        "    for candidato in combinaciones:\n",
        "        playlists_inter = []\n",
        "        for song in candidato:\n",
        "          playlists_inter.append(canciones_playlists[song])\n",
        "        contadorDecombinaciones[candidato] = len(set.intersection(*playlists_inter))\n",
        "    contador_libreria = {subset: veces for subset, veces in contadorDecombinaciones.items() if veces / playlist_tamanio >= min_support} \n",
        "    libreria = contador_libreria.keys() \n",
        "    itemsets_frecuentes_tamaño.extend(libreria)\n",
        "    itemsets_frecuentes[k] = sorted(contador_libreria.items(), key=lambda x: x[1], reverse=True)\n",
        "    k += 1\n",
        "    actual = libreria\n",
        "  # Generamos itemsets usando DataFrame\n",
        "  itemsets_dataframe = pd.DataFrame([item for sublist in itemsets_frecuentes.values() for item in sublist]).round(3)\n",
        "  itemsets_dataframe.columns = [\"itemset\", \"contador_support\"]\n",
        "  itemsets_dataframe[\"support\"] = itemsets_dataframe[\"contador_support\"] / len(playlists)\n",
        "  # La funcion retornara un vector con 4 datos\n",
        "  extra_data = []\n",
        "  # En la primera posicion estaran los itemsets mas frecuentes.\n",
        "  extra_data.append(itemsets_dataframe)\n",
        "  # En la segunda posicion estaran los datos de la playlist para un posterior uso.\n",
        "  extra_data.append(playlists)\n",
        "  # En la tercera posicion estara el registro de las canciones que estan en las playlists.\n",
        "  extra_data.append(canciones_playlists)\n",
        "  # En la cuarta posicion estaran el registro de los itemsets largos para un posterior uso.\n",
        "  extra_data.append(itemsets_frecuentes_tamaño)\n",
        "  return extra_data\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDSh5GSf5fF1"
      },
      "source": [
        "#### **Funcion: generate_association_rules(frequent_itemsets, confidence, lift)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK4OZZiAfqfX"
      },
      "source": [
        "#Funcion para generar las reglas de asociacion\n",
        "def generate_association_rules(frequent_itemsets, confidence, lift):\n",
        "  reglas = [] \n",
        "  for itemset in frequent_itemsets[3]:\n",
        "    #Se forman todas las combinaciones posibles de X -> Y, donde X ⊂ I y Y = I - X\n",
        "    itemset_contador = calcular_interseccion(itemset,frequent_itemsets[2])\n",
        "    itemset_support = itemset_contador / len(frequent_itemsets[0])\n",
        "    for i in range(1, len(itemset) + 1):\n",
        "        for xSet in combinaciones(itemset, i):\n",
        "            xSet = set(xSet)\n",
        "            ySet = set(itemset) - xSet\n",
        "            xSupport = calcular_interseccion(xSet,frequent_itemsets[2]) / len(frequent_itemsets[0])\n",
        "            xySupport = calcular_interseccion(xSet.union(ySet),frequent_itemsets[2]) / len(frequent_itemsets[0])\n",
        "            rule_confidence = xySupport / xSupport\n",
        "            if len(xSet) > 0 and len(ySet) > 0:\n",
        "                ySupport = calcular_interseccion(ySet,frequent_itemsets[2]) / len(frequent_itemsets[0])\n",
        "                rule_lift = xySupport / (xSupport * ySupport)\n",
        "                reglas.append((xSet, ySet, rule_confidence, xySupport, rule_lift))\n",
        "  #Generar dataframe de las reglas de asociacion\n",
        "  reglas_dataframe = pd.DataFrame(data=reglas, columns=[\"X\", \"Y\", \"confidence\", \"support\", \"lift\"]).round(3)\n",
        "  reglas_dataframe[\"X\"] = list(map(tuple, reglas_dataframe[\"X\"]))\n",
        "  reglas_dataframe[\"Y\"] = list(map(tuple, reglas_dataframe[\"Y\"]))\n",
        "\n",
        "  #Hallar las reglas de asociacion de 10 elementos para la confianza\n",
        "  order_by=\"confidence\"\n",
        "  n=10\n",
        "  confidence_df = reglas_dataframe.sort_values(order_by, ascending=False).head(n)\n",
        "\n",
        "  #Hallar las reglas de asociacion de 10 elementos para lift\n",
        "  order_by=\"lift\"\n",
        "  n=10\n",
        "  lift_df2 = reglas_dataframe.sort_values(order_by, ascending=False).head(n)\n",
        "\n",
        "  #Hallar las reglas de asociacion que cumplan con la condicion de confianza y lift\n",
        "  reglas_dataframe[\"len_itemset\"] = reglas_dataframe.apply(lambda x: len(set(x[\"X\"]).union(set(x[\"Y\"]))), axis=1)\n",
        "  reglas_dataframe=reglas_dataframe.sort_values(by=\"len_itemset\", ascending=False)\n",
        "  both_rules = reglas_dataframe[(reglas_dataframe[\"confidence\"] >= confidence) & (reglas_dataframe[\"lift\"] >= lift)]\n",
        "\n",
        "  return confidence_df,lift_df2,both_rules\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_WPXa-_56Qg"
      },
      "source": [
        "### **1.1 Implementar las siguientes funciones secundarias**\n",
        "\n",
        "*   **calcular_inter(subset,canciones_playlist):** Recibe las tuplas de los itemsets para calcular el contador de soporte de un itemset con la lista de canciones en playlist. Una vez obtenidas las listas de reproducción en que aparece cada canción del itemset, se interseca con las listas de reproduccion de playlists. Todos los conjuntos intersecados seran el soporte de determinado itemset.\n",
        "\n",
        "*   **combinations(iterable, r):** Este modulo sirve para generar las tuplas de combinaciones de los itemsets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwzP8KuM57bP"
      },
      "source": [
        "# Modulo para crear interseccion de los itemset\n",
        "def calcular_interseccion(subset,canciones_playlist):\n",
        "    playlists_interset = []\n",
        "    for song in subset:\n",
        "        playlists_interset.append(canciones_playlist[song])\n",
        "    return len(set.intersection(*playlists_interset))\n",
        "    \n",
        "# Modulo para generar combinaciones en los itemsets    \n",
        "def combinaciones(iterable, s):\n",
        "    pool = tuple(iterable)\n",
        "    # determinamos el tamaño del arreglo con len\n",
        "    n = len(pool)\n",
        "    if s > n:\n",
        "        return\n",
        "    indices = list(range(s))\n",
        "    yield tuple(pool[i] for i in indices)\n",
        "    while True:\n",
        "        for i in reversed(range(s)):\n",
        "            if indices[i] != i + n - s:\n",
        "                break\n",
        "        else:\n",
        "            return\n",
        "        indices[i] += 1\n",
        "        for j in range(i + 1, s):\n",
        "            indices[j] = indices[j - 1] + 1\n",
        "        yield tuple(pool[i] for i in indices)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLNx4ygy3XV3"
      },
      "source": [
        "## **2. Aplicar el algoritmo y obtener reglas de asociación**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "XpH0sZPF6jyd",
        "outputId": "b1ee99e6-196f-4c28-8133-51d8f406682e"
      },
      "source": [
        "# Leer datos\n",
        "db = np.load(\"spotify.npy\", allow_pickle = True)\n",
        "# Generamos lositemsets\n",
        "itemsets = get_frequent_itemsets(db,0.01)\n",
        "itemsets[0].sort_values(by=\"support\").head()\n",
        "# Generamos las reglas\n",
        "reglas_confidence,reglas_lift,reglas_ambos = generate_association_rules(itemsets,0.5,0.9)\n",
        "reglas_confidence\n",
        "reglas_lift\n",
        "reglas_ambos.head(10)\n",
        "# Top 4 de las reglas obtenidas.\n",
        "top_4=reglas_lift.head(4)\n",
        "top_4"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>confidence</th>\n",
              "      <th>support</th>\n",
              "      <th>lift</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>(X (feat. Future),)</td>\n",
              "      <td>(No Heart,)</td>\n",
              "      <td>0.505</td>\n",
              "      <td>0.101</td>\n",
              "      <td>3.493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>(No Heart,)</td>\n",
              "      <td>(X (feat. Future),)</td>\n",
              "      <td>0.696</td>\n",
              "      <td>0.101</td>\n",
              "      <td>3.493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>(Chicken Fried,)</td>\n",
              "      <td>(Knee Deep (feat. Jimmy Buffett),)</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.104</td>\n",
              "      <td>3.261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>(Knee Deep (feat. Jimmy Buffett),)</td>\n",
              "      <td>(Chicken Fried,)</td>\n",
              "      <td>0.682</td>\n",
              "      <td>0.104</td>\n",
              "      <td>3.261</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      X  ...   lift\n",
              "197                 (X (feat. Future),)  ...  3.493\n",
              "196                         (No Heart,)  ...  3.493\n",
              "53                     (Chicken Fried,)  ...  3.261\n",
              "52   (Knee Deep (feat. Jimmy Buffett),)  ...  3.261\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1xJXs1C3jpU"
      },
      "source": [
        "## **3. Explicar las reglas obtenidas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iPP2CyH7WxB"
      },
      "source": [
        "Se determino la filtracion de los itemset con mayor frecuencia frente a las playlist ya que se pueden encontrar coincidencias con la busqueda relacionada. \n",
        "Esto tambien varia deacuerdo al grado de certeza establecido en el umbral.\n",
        "\n",
        "\n",
        "**Primera regla:** Los resultados indican que las musicas son del mismo genero esto agrega una relacion a  estos itemset y eleva el valor del umbral. \n",
        "\n",
        "**Segunda regla:** Cumple con lo establecido por que se repite las mismas canciones de la anterior regla y el el umbral de es mayor grado de confianza.\n",
        "\n",
        "**Tercera regla:** Cumple con lo establecido por que la relacion que se da en esta se debe a gustos musicales y por el cual el umbral tambien es mayor.\n",
        "\n",
        "**Cuarta regla:** Cumple con el criterio establecido.\n",
        "\n",
        "**Nota:** De todo esto podemosdeducir que cada vez que haya una relacion este distintas reglas se debera a la relacion que ellas llevan puede ser el genero, artista, banda, etc por el cual el umbral será mayor al incial ya que cuantas mas reglas obtengamos el umbral tendrá un mayor grado de confiabilidad."
      ]
    }
  ]
}